# üç∑ Predicci√≥n de Calidad del Vino ‚Äì Proyecto de Machine Learning

Este proyecto fue desarrollado usando el dataset de **Wine Quality** disponible en [Kaggle](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset). Mi objetivo fue predecir la calidad del vino a partir de sus caracter√≠sticas fisicoqu√≠micas, aplicando t√©cnicas de an√°lisis exploratorio de datos (EDA), limpieza, visualizaci√≥n y modelos de clasificaci√≥n.

## üìå ¬øQu√© hice?

1. **Importaci√≥n y revisi√≥n inicial del dataset**  
   Comenc√© importando el archivo CSV y explorando su estructura general, tipos de datos y presencia de valores nulos o at√≠picos.

2. **An√°lisis exploratorio de datos (EDA)**  
   Realic√© un an√°lisis gr√°fico y estad√≠stico para entender mejor las relaciones entre variables como:  
   - `citric acid`  
   - `volatile acidity`  
   - `residual sugar`  
   - `alcohol`  
   - `quality`  

3. **Tratamiento de valores cero**  
   Identifiqu√© 99 valores "0" en la columna `citric acid`. En vez de eliminarlos autom√°ticamente, analic√© su coherencia con otras variables (por ejemplo, rangos normales de `fixed acidity`, `volatile acidity`, etc.) para evaluar si eran plausibles.

4. **Detecci√≥n de outliers**  
   Utilic√© boxplots y otras herramientas visuales para encontrar valores at√≠picos, los cuales luego revis√© para decidir si deb√≠an ser eliminados o mantenidos.

5. **Modelado predictivo**  
   Entren√© tres modelos:
   - `KNeighborsClassifier` (KNN), ajustando el hiperpar√°metro `K` con validaci√≥n cruzada.
   - `RandomForestClassifier`, aplicando b√∫squeda de hiperpar√°metros (`GridSearchCV`) para optimizar su rendimiento.
   - `LogisticRegression`, como modelo base de referencia.

   Para la regresi√≥n log√≠stica, ajust√© el hiperpar√°metro `C` (que controla la regularizaci√≥n) mediante b√∫squeda en cuadr√≠cula usando `GridSearchCV` y validaci√≥n cruzada. El mejor rendimiento se obtuvo con:
   - `C = 1`
   - `penalty = 'l2'`
   - `solver = 'liblinear'`

   Este modelo sirvi√≥ como base para comparar los resultados con KNN y Random Forest.

6. **Evaluaci√≥n de modelos**  
   Evalu√© el rendimiento usando m√©tricas como `accuracy`, `precision`, `recall`, `f1-score` y matriz de confusi√≥n. Compar√© los tres modelos y document√© sus fortalezas.

7. **Exportaci√≥n**  
   Guard√© el notebook en GitHub y cre√© una versi√≥n de liberaci√≥n del proyecto con una descripci√≥n clara.

## üìÅ Archivo principal

- `CORE_Prediccion_Calidad_VINO.ipynb`


